# -*- coding: utf-8 -*-
"""Copy of text_to_video.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/176NdoALzyM1rRmT6k0IMb8wCvhdA8uSf
"""

# Install all the required libraries
!pip install diffusers transformers accelerate torch

import torch
from diffusers import MotionAdapter, AnimateDiffPipeline, DDIMScheduler
from diffusers.utils import export_to_video

# --- Load the Video Animation Model (AnimateDiff) ---
adapter = MotionAdapter.from_pretrained("guoyww/animatediff-motion-adapter-v1-5-2")

# --- Load the Text-to-Image Model (Stable Diffusion) ---
model_id = "runwayml/stable-diffusion-v1-5"
# Use DDIMScheduler for better video quality
scheduler = DDIMScheduler.from_pretrained(
    model_id, subfolder="scheduler", clip_sample=False, timestep_spacing="linspace", steps_offset=1
)
pipe = AnimateDiffPipeline.from_pretrained(model_id, motion_adapter=adapter, scheduler=scheduler)

# Enable memory-efficient optimizations
pipe.enable_vae_slicing()
pipe.enable_model_cpu_offload()

# Use GPU for processing
pipe.to("cuda")

# --- Your Prompt ---
prompt = "a dolphin walking in slow motion across the savanna, cinematic lighting"

print("Generating video... This may take a minute or two.")

# --- Generate the Video ---
# The output is a list of frames that form the video
output = pipe(prompt=prompt, num_inference_steps=25, guidance_scale=7.5, num_frames=16)
frames = output.frames[0]

# --- Save the Video ---
# Export the frames as an MP4 video file
video_path = "generated_video.mp4"
export_to_video(frames, video_path, fps=8)

print(f"Video saved successfully to {video_path}")

# --- Display the Video in Colab ---
from IPython.display import HTML
from base64 import b64encode

with open(video_path, "rb") as f:
    video_data = f.read()
    video_b64 = b64encode(video_data).decode('utf-8')

HTML(f"""
<video width="512" height="512" controls>
  <source src="data:video/mp4;base64,{video_b64}" type="video/mp4">
</video>
""")

"""this part of code is not working for frontend"""

# Install flask and the new pyngrok library
!pip install flask pyngrok

!mkdir -p templates
!mkdir -p static/css
!mkdir -p static/js

# Commented out IPython magic to ensure Python compatibility.
# # Step 3: Create the HTML file using %%writefile magic command
# %%writefile templates/index.html
# <!DOCTYPE html>
# <html lang="en">
# <head>
#     <meta charset="UTF-8">
#     <title>AI Video Generator</title>
#     <link rel="stylesheet" href="/static/css/style.css">
# </head>
# <body>
#     <div class="container">
#         <h1>AI Video Generator</h1>
#         <input type="text" id="promptInput" placeholder="Enter a prompt...">
#         <button id="generateBtn">Generate Video</button>
#         <div id="status"></div>
#         <div id="videoContainer"></div>
#     </div>
#     <script src="/static/js/main.js"></script>
# </body>
# </html>

# Commented out IPython magic to ensure Python compatibility.
# #Step 4:Create the CSS file
# %%writefile static/css/style.css
# body { font-family: sans-serif; background-color: #f0f2f5; margin: 2em; text-align: center; }
# .container { max-width: 600px; margin: auto; background: white; padding: 2em; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); }
# input { width: 80%; padding: 10px; margin-bottom: 1em; }
# button { padding: 10px 20px; font-size: 1em; cursor: pointer; }
# #status { margin-top: 1em; color: #555; }
# video { margin-top: 1em; max-width: 100%; }

# Commented out IPython magic to ensure Python compatibility.
# # Step 5: Create the JavaScript file
# %%writefile static/js/main.js
# document.addEventListener('DOMContentLoaded', () => {
#     const promptInput = document.getElementById('promptInput');
#     const generateBtn = document.getElementById('generateBtn');
#     const statusDiv = document.getElementById('status');
#     const videoContainer = document.getElementById('videoContainer');
# 
#     generateBtn.addEventListener('click', generateVideo);
# 
#     async function generateVideo() {
#         const prompt = promptInput.value;
#         statusDiv.innerText = 'Generating... Please wait.';
#         videoContainer.innerHTML = '';
#         generateBtn.disabled = true;
# 
#         try {
#             // NOTE: Replace with your actual API call logic
#             const response = await fetch('/generate-video', {
#                 method: 'POST',
#                 headers: { 'Content-Type': 'application/json' },
#                 body: JSON.stringify({ prompt: prompt })
#             });
#             const data = await response.json();
# 
#             if (data.video_url) {
#                 statusDiv.innerText = 'Video is ready!';
#                 videoContainer.innerHTML = `<video src="${data.video_url}" controls autoplay></video>`;
#             } else {
#                  statusDiv.innerText = `Error: ${data.error}`;
#             }
# 
#         } catch (error) {
#             statusDiv.innerText = `Error: ${error.message}`;
#         } finally {
#             generateBtn.disabled = false;
#         }
#     }
# });

!ngrok config add-authtoken 31JsIq7677nA5JsoPgNCmWCjfjj_25fWhckN84cGYPUTrCLGJ

# Step 6: Write the Flask App and run it with pyngrok
from flask import Flask, render_template, jsonify
from pyngrok import ngrok
import time

# Set up the ngrok tunnel
port_no = 5000
public_url = ngrok.connect(port_no).public_url
print(f" * ngrok tunnel \"{public_url}\" -> \"http://127.0.0.1:{port_no}\"")

app = Flask(__name__)

# ... (The rest of your Flask app code remains the same) ...
@app.route("/")
def index():
    return render_template('index.html')

@app.route("/generate-video", methods=['POST'])
def generate_video():
    # This is a MOCK function for the example
    print("Generating video...")
    time.sleep(10)
    print("Video generated!")
    mock_video_url = "http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4"
    return jsonify({"video_url": mock_video_url})

if __name__ == '__main__':
    app.run()

!pip install nbstripout
nbstripout text_to_video.ipynb

